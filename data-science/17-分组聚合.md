## 分组聚合
大数据分析的一项基本内容是有效的汇总：计算诸如sum（），mean（），mid（），min（）和max（）之类的聚合，其中单个数字可以洞悉潜在大数据的性质数据集。在本节中，我们将探讨Pandas中的聚合，从类似于在NumPy阵列上看到的简单操作，到基于groupby概念的更复杂的操作。
为了方便起见，我们将使用与上一节相同的显示功能：
```py
import numpy as np
import pandas as pd

class display(object):
    """Display HTML representation of multiple objects"""
    template = """<div style="float: left; padding: 10px;">
    <p style='font-family:"Courier New", Courier, monospace'>{0}</p>{1}
    </div>"""
    def __init__(self, *args):
        self.args = args
        
    def _repr_html_(self):
        return '\n'.join(self.template.format(a, eval(a)._repr_html_())
                         for a in self.args)
    
    def __repr__(self):
        return '\n\n'.join(a + '\n' + repr(eval(a))
                           for a in self.args)
```
### 行星数据
在这里，我们将使用可通过Seaborn软件包获得的Planets数据集（请参阅“ Seaborn的可视化”）。它提供了天文学家在其他恒星周围发现的行星信息：
```py
import seaborn as sns
planets = sns.load_dataset('planets')
planets.shape
```
### 使用pandas 简单聚合操作
之前，我们探讨了一些可用于NumPy数组的数据聚合（“聚合：最小，最大和介于两者之间的所有数据”）。与一维NumPy数组一样，对于Pandas series，聚合返回单个值， 下面是一些series和dataframe的示例
```py
In [45]: rng=np.random.RandomState(0)
In [46]: ser=pd.Series(rng.rand(5))
In [47]: ser
Out[47]: 
0    0.548814
1    0.715189
2    0.602763
3    0.544883
4    0.423655
dtype: float64

In [48]: ser.sum()
Out[48]: 2.83530422870719

In [49]: ser.mean()
Out[49]: 0.567060845741438
## DataFrame
In [51]: df =  pd.DataFrame({'A':rng.rand(4),'B':rng.rand(4)})

In [52]: df
Out[52]: 
          A         B
0  0.071036  0.778157
1  0.087129  0.870012
2  0.020218  0.978618
3  0.832620  0.799159

In [53]: df.mean()
Out[53]: 
A    0.252751
B    0.856486
dtype: float64

In [54]: df.sum()
Out[54]: 
A    1.011004
B    3.425946
dtype: float64
## 通过指定axis参数，您可以改为在每一行中进行汇总：
In [56]: df.sum(axis='columns')
Out[56]: 
0    0.849193
1    0.957141
2    0.998837
3    1.631778
dtype: float64
# 或者
In [57]: df.sum(axis=1)
Out[57]: 
0    0.849193
1    0.957141
2    0.998837
3    1.631778
dtype: float64

```
Pandas Series和DataFrames包含集合中提到的所有常见集合：最小，最大和介于两者之间的所有内容；此外，还有一种便捷的方法describe（），它为每列计算几个通用聚合并返回结果。让我们在Planets数据上使用它，现在删除缺少值的行：
```py
In [59]: planets.dropna().describe()
Out[59]: 
          number  orbital_period        mass    distance         year
count  498.00000      498.000000  498.000000  498.000000   498.000000
mean     1.73494      835.778671    2.509320   52.068213  2007.377510
std      1.17572     1469.128259    3.636274   46.596041     4.167284
min      1.00000        1.328300    0.003600    1.350000  1989.000000
25%      1.00000       38.272250    0.212500   24.497500  2005.000000
50%      1.00000      357.000000    1.245000   39.940000  2009.000000
75%      2.00000      999.600000    2.867500   59.332500  2011.000000
max      6.00000    17337.500000   25.000000  354.000000  2014.000000
```
这可能是开始理解数据集整体属性的有用方法。例如，我们在“年”列中看到，尽管早在1989年就发现了系外行星，但直到2010年或之后才发现所有已知expolanets 。这在很大程度上要归功于 Kepler，这是一种天基望远镜，专门用于发现其他恒星周围的黯淡行星。
下表总结了其他一些内置的Pandas聚合：
```
汇总说明
    count（）项目总数
    first（），last（）第一项和最后一项
    mean（），median（）平均值和中位数
    min（），max（）最小和最大
    std（），var（）标准偏差和方差
    mad（）平均绝对偏差
    prod（）所有项目的乘积
    sum（）所有项目的总和
```
这些都是DataFrame和Series对象的方法。
但是，要深入研究数据，简单的聚合通常是不够的。数据汇总的下一个层次是groupby操作，它使您可以快速有效地计算数据子集上的聚合。
### 分组：拆分，应用，合并

简单的聚合可以使您的数据集更加有趣，但是通常我们希望有条件地在某些标签或索引上进行聚合：这是在所谓的groupby操作中实现的。 "group by" 这个名称来自SQL数据库语言中的一个命令，但是用Rstats的成名人物Hadley Wickham最初创造的术语来思考它可能更具有启发性：拆分，应用，组合。
#### Split, apply, combine
下图说明了此拆分应用合并操作的一个规范示例，其中 "apply" 是求和聚合。
![示例图](https://github.com/xiongzhenggang/xiongzhenggang.github.io/blob/master/data-science/image/03.08-split-apply-combine.png)

这清楚地表明了groupby的成就：

    拆分步骤涉及根据指定键的值对DataFrame进行分解和分组。
    应用步骤涉及在各个组内计算一些功能，通常是合计，转换或过滤。
    Combine步骤将这些操作的结果合并到一个输出数组中。

尽管可以肯定地使用前面介绍的掩蔽，聚合和合并命令的组合手动完成此操作，但重要的认识是不需要拆分中间拆分。相反，GroupBy可以（通常）对数据进行一次传递，从而更新沿途各组的总和，均值，计数，最小值或其他总计。 GroupBy的强大之处在于它使这些步骤抽象化：用户无需考虑如何在后台进行计算，而可以考虑整个操作。
作为一个具体示例，让我们看一下使用Pandas进行此图所示的计算。我们将从创建输入DataFrame开始：
```py
In [60]:df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],
    ...:                    'data': range(6)}, columns=['key', 'data'])
    ...: df
Out[60]: 
  key  data
0   A     0
1   B     1
2   C     2
3   A     3
4   B     4
5   C     5
# 分组
In [61]: df.groupby('key')
Out[61]: <pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001DC8C55E580>
```
请注意，返回的不是一组DataFrame，而是一个DataFrameGroupBy对象。这个对象就是魔术的所在：您可以将其视为DataFrame的特殊视图，该视图准备深入研究组，但在应用聚合之前不会进行实际计算。这种"lazy evaluation"方法意味着可以以对用户几乎透明的方式非常有效地实施常见的聚合。
 
为了产生结果，我们可以将聚合应用于此DataFrameGroupBy对象，该对象将执行适当的apply / combine步骤以产生所需的结果：
```py
In [62]: df.groupby('key').sum()
Out[62]: 
     data
key
A       3
B       5
C       7
```
sum（）方法在这里只是一种可能性；您几乎可以应用任何常见的Pandas或NumPy聚合函数，以及几乎任何有效的DataFrame操作，正如我们将在以下讨论中看到的那样。
### grouby 对象
 
GroupBy对象是一个非常灵活的抽象。在许多方面，您可以简单地将其视为DataFrame的集合来处理，并且可以做很多困难的事情。让我们来看一些使用Planets数据的示例。

GroupBy提供的最重要的操作也许是聚合，过滤，转换和应用。我们将在“聚合，过滤，转换，应用”中更全面地讨论这些功能，但是在此之前，我们先介绍一些基本GroupBy操作可以使用的其他功能。
#### 列索引
GroupBy对象以与DataFrame相同的方式支持列索引，并返回修改后的GroupBy对象。例如：
```py
In [64]: planets.groupby('method')
Out[64]: <pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001DCFFFDC130>
#在这里，我们通过参考原始DataFrame组的列名选择了一个特定的Series组。与GroupBy对象一样，在我们对该对象调用一些聚合之前，不会进行任何计算：
In [65]: planets.groupby('method')['orbital_period']
Out[65]: <pandas.core.groupby.generic.SeriesGroupBy object at 0x000001DCFFA75AC0>
# 我们取SeriesGroupBy的中位数
In [66]: planets.groupby('method')['orbital_period'].median()
Out[66]: 
method
Astrometry                         631.180000
Eclipse Timing Variations         4343.500000
Imaging                          27500.000000
Microlensing                      3300.000000
Orbital Brightness Modulation        0.342887
Pulsar Timing                       66.541900
Pulsation Timing Variations       1170.000000
Radial Velocity                    360.200000
Transit                              5.714932
Transit Timing Variations           57.011000
Name: orbital_period, dtype: float64
```
这给出了每种方法均敏感的总体轨道周期（以天为单位）的概念。
### 组迭代
GroupBy对象支持在组上进行直接迭代，将每个组作为Series或DataFrame返回：
```py
In [69]: for (method,group) in planets.groupby('method'):
    ...:     print("{0:30s} shape={1}".format(method,group.shape))
    ...: 
Astrometry                     shape=(2, 6)
Eclipse Timing Variations      shape=(9, 6)
Imaging                        shape=(38, 6)
Microlensing                   shape=(23, 6)
Orbital Brightness Modulation  shape=(3, 6)
Pulsar Timing                  shape=(5, 6)
Pulsation Timing Variations    shape=(1, 6)
Radial Velocity                shape=(553, 6)
Transit                        shape=(397, 6)
Transit Timing Variations      shape=(4, 6)
```
这对于手动执行某些操作可能很有用，尽管使用内置的应用功能通常要快得多，我们将在稍后进行讨论。
###  派送方式
通过一些Python类魔术，GroupBy对象未明确实现的任何方法都将通过并在组上调用，无论它们是DataFrame还是Series对象。例如，可以使用DataFrames的describe（）方法执行一组描述数据中每个组的聚合：
```py
In [70]: planets.groupby('method')['year'].describe().unstack()
Out[70]: 
       method
count  Astrometry                          2.0
       Eclipse Timing Variations           9.0
       Imaging                            38.0
       Microlensing                       23.0
       Orbital Brightness Modulation       3.0
                                         ...
max    Pulsar Timing                    2011.0
       Pulsation Timing Variations      2007.0
       Radial Velocity                  2014.0
       Transit                          2014.0
       Transit Timing Variations        2014.0
Length: 80, dtype: float64
```
### Aggregate, filter, transform, apply
前面的讨论着重于合并操作的聚合，但是还有更多可用选项。特别是，GroupBy对象具有Aggregate（），filter（），transform（）和apply（）方法，这些方法在组合分组的数据之前可以有效地实现各种有用的操作。
```py
In [175]: rng = np.random.RandomState(0)
     ...: df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],
     ...:                    'data1': range(6),
     ...:                    'data2': rng.randint(0, 10, 6)},
     ...:                    columns = ['key', 'data1', 'data2'])
     ...: df
Out[175]: 
  key  data1  data2
0   A      0      5
1   B      1      0
2   C      2      3
3   A      3      3
4   B      4      7
5   C      5      9
```
### Aggregation
现在，我们已经熟悉了具有sum(), median()和类似内容的GroupBy聚合，但是aggregate（）方法提供了更大的灵活性。它可以采用字符串，函数或其列表，然后一次计算所有聚合。这是结合所有这些的简单示例：
```py
In [176]: df.groupby("key").aggregate(['min', np.median, max])
Out[176]: 
    data1            data2
      min median max   min median max
key
A       0    1.5   3     3    4.0   5
B       1    2.5   4     0    3.5   7
C       2    3.5   5     3    6.0   9
```
 
另一个有用的模式是将字典映射的列名传递给要对该列应用的操作：
```py
In [177]: df.groupby("key").aggregate({'data1':'min','data2':'max'})
Out[177]: 
     data1  data2
key
A        0      5
B        1      7
C        2      9
```
### Filtering
过滤操作使您可以基于组属性删除数据。例如，我们可能希望保留标准偏差大于某个临界值的所有组：
```py
In [182]: def filter_func(x):
     ...:     return x['data2'].std() > 4
     ...: 
     ...: display('df', "df.groupby('key').std()", "df.groupby('key').filter(filter_func)")
Out[182]: 
df
  key  data1  data2
0   A      0      5
1   B      1      0
2   C      2      3
3   A      3      3
4   B      4      7
5   C      5      9

df.groupby('key').std()
       data1     data2
key
A    2.12132  1.414214
B    2.12132  4.949747
C    2.12132  4.242641

df.groupby('key').filter(filter_func)
  key  data1  data2
1   B      1      0
2   C      2      3
4   B      4      7
5   C      5      9
```
过滤器函数应返回一个布尔值，该值指定该组是否通过过滤。在这里，由于组A的标准偏差不大于4，因此将其从结果中删除。
### Transformation
虽然聚合必须返回数据的精简版本，但转换可以返回完整数据的某些转换版本以重新组合。对于这种变换，输出与输入的形状相同。一个常见的示例是通过减去分组平均值来居中数据：
```py
In [185]: df.groupby('key').transform(lambda x : x-x.mean())
Out[185]: 
   data1  data2
0   -1.5    1.0
1   -1.5   -3.5
2   -1.5   -3.0
3    1.5   -1.0
4    1.5    3.5
5    1.5    3.0
```
### apply() 
 
apply（）方法使您可以将任意函数应用于分组结果。该函数应采用一个DataFrame，并返回Pandas对象（例如DataFrame，Series）或标量；合并操作将根据返回的输出类型进行调整。

例如，这是一个apply（），它通过第二列的总和来归一化第一列：
```py
In [187]: def norm_by_data2(x):
     ...:     # x is a DataFrame of group values
     ...:     x['data1'] /= x['data2'].sum()
     ...:     return x
     ...: 
     ...: display('df', "df.groupby('key').apply(norm_by_data2)")
Out[187]: 
df
  key  data1  data2
0   A      0      5
1   B      1      0
2   C      2      3
3   A      3      3
4   B      4      7
5   C      5      9

df.groupby('key').apply(norm_by_data2)
  key     data1  data2
0   A  0.000000      5
1   B  0.142857      0
2   C  0.166667      3
3   A  0.375000      3
4   B  0.571429      7
5   C  0.416667      9
```
GroupBy中的apply（）非常灵活：唯一的标准是该函数采用DataFrame并返回Pandas对象或标量；您在中间所做的一切取决于您！
### 指定分割键
在前面介绍的简单示例中，我们将DataFrame拆分为一个列名。这只是可用于定义组的众多选项之一，我们将在此处介绍用于组指定的其他一些选项。

#### 分组键的列表，数组，系列或索引
```py
In [188]: L = [0, 1, 0, 1, 2, 0]
     ...: display('df', 'df.groupby(L).sum()')
Out[188]: 
df
  key  data1  data2
0   A      0      5
1   B      1      0
2   C      2      3
3   A      3      3
4   B      4      7
5   C      5      9

df.groupby(L).sum()
   data1  data2
0      7     17
1      4      3
2      4      7
```
#### dictionary or series mapping index to group
另一种方法是提供将索引值映射到组键的字典：

```py
In [189]: df2 = df.set_index('key')
     ...: mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}
     ...: display('df2', 'df2.groupby(mapping).sum()')
Out[189]: 
df2
     data1  data2
key
A        0      5
B        1      0
C        2      3
A        3      3
B        4      7
C        5      9

df2.groupby(mapping).sum()
           data1  data2
consonant     12     19
vowel          3      8
```
### Python  函数
与映射类似，您可以传递将输入索引值并输出组的任何Python函数：
```py
In [193]: display('df2', 'df2.groupby(str.lower).mean()')
Out[193]: 
df2
     data1  data2
key
A        0      5
B        1      0
C        2      3
A        3      3
B        4      7
C        5      9

df2.groupby(str.lower).mean()
   data1  data2
a    1.5    4.0
b    2.5    3.5
c    3.5    6.0
```

### 有效密钥列表
此外，可以将任何前述关键选择组合在一起以对多索引进行分组：
```py
In [194]: df2.groupby([str.lower, mapping]).mean()
Out[194]: 
             data1  data2
a vowel        1.5    4.0
b consonant    2.5    3.5
```