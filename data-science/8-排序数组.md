## 数组排序
 到目前为止，我们主要关注的是使用NumPy访问和处理数组数据的工具。本节介绍与NumPy数组中的值排序有关的算法。这些算法是计算机科学入门课程中最喜欢的主题：有关插入排序，选择排序，合并排序，快速排序，冒泡排序等等。所有这些都是完成类似任务的方法：对列表或数组中的值进行排序。
 下面我们看下选择排序的例子
 ```py
 In [2]: def selection_sort(x):
   ...:     for i in range(len(x)):
# argmin 取得最小值得下标
   ...:         swapIndex= i + np.argmin(x[i:])
   ...:         (x[i],x[swapIndex])=(x[swapIndex],x[i])
   ...:     return x

In [5]: n=np.random.randint(10,size=8)
In [8]: print(selection_sort(n))
[1 4 5 7 8 8 8 9]
 ```
正如任何一年级计算机科学专业的人都会告诉您的那样，选择排序因其简单性而有用，但太慢而无法用于较大的阵列。对于N个值的列表，它需要N个循环，每个循环进行约N次比较以找到交换值。根据通常用于表征这些算法的“大O”符号（[请参阅大O符号](https://jakevdp.github.io/PythonDataScienceHandbook/02.08-sorting.html#Aside:-Big-O-Notation)），选择排序平均值为O [N2]：如果将列表中的项目数加倍，执行时间将增加约四倍。

看一下Python内置函数，然后看一下NumPy中包含的，为NumPy数组优化的例程
### 在NumPy中快速排序：np.sort和np.argsort
尽管Python具有内置的用于列表的sort和sorted函数，但由于NumPy的np.sort函数对于我们的目的而言更加高效和有用，因此我们在此不进行讨论。默认情况下，np.sort使用O [NlogN]快速排序算法，尽管mergesort和heapsort也可用。对于大多数应用程序，默认快速排序已绰绰有余。
```py
In [9]: x = np.array([2, 1, 4, 3, 5])
   ...: np.sort(x)
Out[9]: array([1, 2, 3, 4, 5])
#一个相关的函数是argsort，它返回已排序元素的索引：
In [10]: i = np.argsort(x)
In [11]: i
# 返回得是索引数组
Out[11]: array([1, 0, 3, 2, 4], dtype=int64)
In [12]: x[i]
Out[12]: array([1, 2, 3, 4, 5])
```
### 沿行或列排序
NumPy排序算法的一个有用功能是能够使用axis参数沿多维数组的特定行或列进行排序。例如：
```py
In [15]: rand = np.random.RandomState(42)
    ...: X = rand.randint(0, 10, (4, 6))
    ...: print(X)
[[6 3 7 4 6 9]
 [2 6 7 4 3 7]
 [7 2 5 4 1 7]
 [5 1 4 0 9 5]]
# 对列排序
In [16]: np.sort(X, axis=0)
Out[16]: 
array([[2, 1, 4, 0, 1, 5],
       [5, 2, 5, 4, 3, 7],
       [6, 3, 7, 4, 6, 7],
       [7, 6, 7, 4, 9, 9]])
#对行排序
In [17]: np.sort(X,axis=1)
Out[17]: 
array([[3, 4, 6, 6, 7, 9],
       [2, 3, 4, 6, 7, 7],
       [1, 2, 4, 5, 7, 7],
       [0, 1, 4, 5, 5, 9]])
 ```
* 这会将每一行或每一列视为一个独立的数组，并且行或列值之间的任何关系都将丢失！
### 部分排序

有时我们对排序整个数组不感兴趣，而只是想找到数组中的k个最小值。 NumPy在np.partition函数中提供了此功能。 np.partition接受一个数组和一个数字K;结果返回一个新的数组，该数组在分区的左侧是查找得K个最小值，其余的值以任意顺序在右侧：
```py
In [18]: x=np.array([3,2,6,4,1])
In [19]: np.partition(x,3)
Out[19]: array([2, 1, 3, 4, 6])
# 同样可以作用在多维数组上。查找所有行中2个最小值
In [20]: np.partition(X, 2, axis=1)
Out[20]: 
array([[3, 4, 6, 7, 6, 9],
       [2, 3, 4, 7, 6, 7],
       [1, 2, 4, 5, 7, 7],
       [0, 1, 4, 5, 9, 5]])
```
最后，np.argsort计算排序的索引一样，np.argpartition计算分区的索引。
#### k临近元素

让我们快速了解如何在多个轴上使用此argsort函数查找集合中每个点的最近邻居。我们将从在二维平面上随机创建10个点的集合开始。使用标准约定，我们将这些排列成10×2的数组，可以理解为10个点，每个点[x,y]：
```py
import matplotlib.pyplot as plt
import seaborn; seaborn.set() # Plot styling
import numpy as np
# 创建随机0-1 之间得十个点
X=np.random.randn(10,2)
plt.scatter(X[:, 0], X[:, 1], s=100);
plt.show()
```
![图片](https://github.com/xiongzhenggang/xiongzhenggang.github.io/blob/master/data-science/image/nearest_1.png)

现在，我们将计算每对点之间的距离。回想一下，两点之间的平方距离是每个维度的平方差之和；使用NumPy提供的高效广播（[数组计算：广播](./5-Numpy数组广播.md)）和聚合（[聚合：最小，最大和介于两者之间的所有例程](./4-Numpy通用函数.md)）例程，我们可以在单行代码中计算平方距离的矩阵：
> dist_sq = np.sum((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2, axis=-1)
此操作包含很多内容，如果不熟悉NumPy的广播规则，可能会有些困惑。当遇到这样的代码时，可将其分解为各个组成部分步骤可能会很有用：
```py
# 理解X[:, np.newaxis, :]和 X[np.newaxis, :, :] 这么做是为了后续广播扩展。
# 扩展形成维度(10, 1, 2)-(1, 10, 2)=(10, 10, 2).。注意得到10*10*2的数组形如[[[]....[]]...[[]...[]]] 其中每一[[]....[]]包含的都是选取的一个点到其他各个点坐标差
In [41]: X=np.random.randn(10,2)
In [42]: differences = X[:, np.newaxis, :] - X[np.newaxis, :, :]
    ...: differences.shape
Out[42]: (10, 10, 2)
#分别对坐标差平方
In [46]: sq_differences = differences ** 2
    ...: sq_differences.shape
Out[46]: (10, 10, 2)
In [47]: # axis选择-1 是将三维数组中一维数组[x^2,y^2]进行相加,最後10*10*2=>10*10
    ...: dist_sq = sq_differences.sum(-1)
    ...: dist_sq.shape
Out[47]: (10, 10)
# 测试下对角线的值为是否0，目的是判斷自身的點和自身的点距离为0
In [65]: dist_sq.diagonal()
Out[65]: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
#返回排序后的索引数组
In [66]: nearest = np.argsort(dist_sq, axis=1)
    ...: print(nearest)
[[0 3 7 5 9 4 1 2 6 8]
 [1 4 8 7 9 2 5 3 0 6]
 [2 4 3 7 1 8 0 9 5 6]
 [3 0 7 9 5 4 2 1 6 8]
 [4 1 2 7 8 3 9 0 5 6]
 [5 9 7 6 0 3 1 4 8 2]
 [6 5 9 7 0 1 3 4 8 2]
 [7 9 3 0 5 4 1 2 8 6]
 [8 1 4 2 7 9 5 3 0 6]
 [9 5 7 0 1 3 6 4 8 2]]
```
请注意，第一列按顺序从0到9给出了数字：这是由于每个点的最接近邻居本身就是我们所期望的事实。

通过在此处使用完整的排序，实际上我们完成了比这种情况下需要做的工作更多的工作。如果我们只是对最近的k感兴趣
邻居，我们需要的是对每一行进行分区，以使最小的k + 1平方距离首先出现，而较大的距离将填充数组的其余位置。我们可以使用np.argpartition函数来做到这一点：
```py
#argpartition 按照列返回K+1个
In [87]: K = 2
    ...: nearest_partition = np.argpartition(dist_sq, K + 1, axis=1)
In [88]: nearest_partition
Out[88]: 
array([[0, 3, 7, 5, 9, 1, 6, 2, 8, 4],
       [1, 4, 8, 7, 9, 5, 6, 3, 2, 0],
       [3, 2, 4, 7, 1, 8, 0, 6, 5, 9],
       [3, 0, 7, 9, 1, 5, 6, 2, 8, 4],
       [1, 2, 4, 7, 3, 8, 9, 6, 5, 0],
       [5, 9, 7, 6, 0, 1, 3, 2, 8, 4],
       [6, 5, 9, 7, 0, 1, 3, 2, 8, 4],
       [3, 9, 7, 0, 1, 5, 6, 2, 8, 4],
       [8, 1, 4, 2, 7, 9, 6, 5, 3, 0],
       [5, 9, 7, 0, 1, 3, 6, 2, 8, 4]], dtype=int64)
```

为了可视化此邻居网络，让我们快速绘制点以及代表从每个点到它的两个最近邻居的连接的线：

作图源码如下：
```py
import matplotlib.pyplot as plt
import seaborn; seaborn.set() # Plot styling
import numpy as np

X=np.random.randn(10,2)
differences = X[:, np.newaxis, :] - X[np.newaxis, :, :]
sq_differences = differences ** 2
dist_sq = sq_differences.sum(-1)
# draw lines from each point to its two nearest neighbors
plt.scatter(X[:, 0], X[:, 1], s=100)
K = 2
nearest_partition = np.argpartition(dist_sq, K + 1, axis=1)
#循环取原数组每一个点和该点对应最近的K+1个点，画图
for i in range(X.shape[0]):
    for j in nearest_partition[i, :K+1]:
        # plot a line from X[i] to X[j]
        # zip()函数的定义从参数中的多个迭代器取元素组合成一个新的迭代器；
        #*zip()函数是zip()函数的逆过程，将zip对象变成原先组合前的数据。
        plt.plot(*zip(X[j], X[i]), color='black')
plt.show()
```
![图片](https://github.com/xiongzhenggang/xiongzhenggang.github.io/blob/master/data-science/image/8-nearest.png)
图中的每个点都有绘制到其两个最近邻点的线。乍看之下，有些点有两条以上的线可能看起来很奇怪：这是由于以下事实：如果点A是点B的两个最接近的邻居之一，则不一定意味着点B是点A的两个最近邻居之一。

尽管这种方法的广播和逐行排序似乎不如编写循环那么简单，但事实证明，这是在Python中处理此数据的非常有效的方法。您可能会尝试通过手动遍历数据并分别对每组邻居进行排序来进行相同类型的操作，但这几乎肯定会导致算法比我们使用的矢量化版本慢。这种方法的优点在于，它的编写方式与输入数据的大小无关：我们可以轻松地计算任意数量维度中100或1,000,000个点之间的邻居，并且代码看起来相同。

最后，我将指出，在进行非常大的最近邻居搜索时，有一些基于树的和/或近似算法可以缩放为O [NlogN]或更好，而不是蛮力算法的O [N2]。一个例子是在[Scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html)中实现的KD-Tree。

#### 大O表示法
Big-O表示法是一种描述算法的操作数如何随着输入大小的增长而扩展的方法。正确使用它是在计算机科学理论领域中的深入研究，并将其与相关的small-o表示法，big-θ表示法，big-Ω表示法以及它们的许多混合突变体仔细地区分开。在数据科学世界中，更为普遍的是使用big-O表示法
从广义上讲，Big-O表示法告诉您算法在增加数据量时将花费多少时间。如果您有一个O [N]（读取为“ N阶”）算法，该算法需要1秒才能对长度为N = 1,000的列表进行操作，那么对于长度为N = 5,000的列表，您应该花费大约5秒钟的时间。如果您有一个O [N2]（读取为“ N阶平方”）算法，则对于N = 1000，它需要花费1秒的时间，对于N = 5000，您应该期望它花费大约25秒的时间。
为了我们的目的，N通常表示数据集大小的某些方面（点数，维数等）。当尝试分析数十亿或数万亿个样本时，O [N]和O [N2]之间的差值可能微不足道！
请注意，big-O表示法本身不会告诉您计算的实际挂钟时间，而只会告诉您更改N时的缩放比例。通常，例如，O [N]算法被认为具有更好的缩放比例比O [N2]算法要好，这是有充分理由的。但是特别是对于小型数据集，具有更好缩放比例的算法可能不会更快。例如，在给定问题中，O [N2]算法可能需要0.01秒，而“更好”的O [N]算法可能需要1秒。但是，将N放大1000倍，O [N]算法将获胜。